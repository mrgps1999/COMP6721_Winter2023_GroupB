{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Data():\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(r'C:\\Users\\Shree\\Desktop\\AI_PROJECT\\Animal Classification\\Final_Dataset\\dataset1\\train', transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(r'C:\\Users\\Shree\\Desktop\\AI_PROJECT\\Animal Classification\\Final_Dataset\\dataset1\\val', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(r'C:\\Users\\Shree\\Desktop\\AI_PROJECT\\Animal Classification\\Final_Dataset\\dataset1\\test', transform=transform)\n",
    "\n",
    "    #print(train_dataset.class_to_idx)\n",
    "    #print(test_dataset.class_to_idx)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    return train_loader,val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=640, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=640, out_features=320, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=320, out_features=160, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=160, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Model():\n",
    "    model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    #print(num_ftrs)\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs,640),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.1),\n",
    "    \n",
    "    nn.Linear(640,320),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.1),\n",
    "    \n",
    "    nn.Linear(320,160),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.1),\n",
    "    \n",
    "    nn.Linear(160, 2)\n",
    "    )\n",
    "    return model.to(device)\n",
    "Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "y_expected_train = []\n",
    "y_val = []\n",
    "y_expected_val = []\n",
    "y_test = []\n",
    "y_expected_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch, step=5):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #print(torch.cuda.is_available())\n",
    "        total =0\n",
    "        correct = 0\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        #print(predicted,type(predicted))\n",
    "        #print(labels,type(labels))\n",
    "        output = model(images)\n",
    "        \n",
    "        loss = criterion(output,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        y_train.extend(predicted.to(torch.device('cpu')))\n",
    "        y_expected_train.extend(labels.to(torch.device('cpu')))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        #print( f'Training Accuracy: {accuracy:.2f}%')\n",
    "            \n",
    "        if i%step==0:\n",
    "            print('EPOCH {} | ITER {} | AVG_LOSS {} | Train_ACC {}'.format(epoch, i, loss,accuracy))\n",
    "        writer.add_scalar('TRAIN_LOSS', loss, epoch)\n",
    "        \n",
    "    return loss ,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, test_loader, criterion, optimizer, epoch, step=5):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            #print(inputs.shape)\n",
    "            #print(labels.shape)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted,type(predicted))\n",
    "            #print(labels,type(labels))\n",
    "            y_val.extend(predicted.to(torch.device('cpu')))\n",
    "            y_expected_val.extend(labels.to(torch.device('cpu')))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f'Val Accuracy: {accuracy:.2f}%')\n",
    "            return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, optimizer, epoch, step=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            #print(inputs.shape)\n",
    "            #print(labels.shape)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted,type(predicted))\n",
    "            #print(labels,type(labels))\n",
    "            y_test.extend(predicted.to(torch.device('cpu')))\n",
    "            y_expected_test.extend(labels.to(torch.device('cpu')))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "            return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "EPOCH 0 | ITER 0 | AVG_LOSS 0.7009494304656982 | Train_ACC 46.875\n",
      "EPOCH 0 | ITER 5 | AVG_LOSS 0.6753954887390137 | Train_ACC 56.25\n",
      "EPOCH 0 | ITER 10 | AVG_LOSS 0.6931236386299133 | Train_ACC 53.125\n",
      "EPOCH 0 | ITER 15 | AVG_LOSS 0.6917001605033875 | Train_ACC 53.125\n",
      "EPOCH 0 | ITER 20 | AVG_LOSS 0.6820389628410339 | Train_ACC 62.5\n",
      "EPOCH 0 | ITER 25 | AVG_LOSS 0.7241309881210327 | Train_ACC 46.875\n",
      "EPOCH 0 | ITER 30 | AVG_LOSS 0.680141031742096 | Train_ACC 62.5\n",
      "EPOCH 0 | ITER 35 | AVG_LOSS 0.6256160736083984 | Train_ACC 56.25\n",
      "EPOCH 0 | ITER 40 | AVG_LOSS 0.650295078754425 | Train_ACC 68.75\n",
      "EPOCH 0 | ITER 45 | AVG_LOSS 0.6570795178413391 | Train_ACC 62.5\n",
      "EPOCH 0 | ITER 50 | AVG_LOSS 0.6937109231948853 | Train_ACC 59.375\n",
      "EPOCH 0 | ITER 55 | AVG_LOSS 0.678638756275177 | Train_ACC 56.25\n",
      "EPOCH 0 | ITER 60 | AVG_LOSS 0.6401710510253906 | Train_ACC 68.75\n",
      "EPOCH 0 | ITER 65 | AVG_LOSS 0.5557555556297302 | Train_ACC 78.125\n",
      "EPOCH 0 | ITER 70 | AVG_LOSS 0.6394736170768738 | Train_ACC 62.5\n",
      "EPOCH 0 | ITER 75 | AVG_LOSS 0.5888948440551758 | Train_ACC 71.875\n",
      "EPOCH 0 | ITER 80 | AVG_LOSS 0.6808818578720093 | Train_ACC 56.25\n",
      "EPOCH 0 | ITER 85 | AVG_LOSS 0.6081809997558594 | Train_ACC 65.625\n",
      "EPOCH 0 | ITER 90 | AVG_LOSS 0.6194260716438293 | Train_ACC 65.625\n",
      "EPOCH 0 | ITER 95 | AVG_LOSS 0.6676449775695801 | Train_ACC 59.375\n",
      "EPOCH 0 | ITER 100 | AVG_LOSS 0.6941426992416382 | Train_ACC 50.0\n",
      "EPOCH 0 | ITER 105 | AVG_LOSS 0.5899277329444885 | Train_ACC 68.75\n",
      "EPOCH 0 | ITER 110 | AVG_LOSS 0.6325449347496033 | Train_ACC 68.75\n",
      "EPOCH 0 | ITER 115 | AVG_LOSS 0.766125500202179 | Train_ACC 62.5\n",
      "EPOCH 0 | ITER 120 | AVG_LOSS 0.6376118063926697 | Train_ACC 59.375\n",
      "Val Accuracy: 59.38%\n",
      "Test Accuracy: 31.25%\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 0 | LOSS 0.692050576210022 | TIME 869.3953242301941\n",
      "--------------------------------------------------\n",
      "\n",
      "EPOCH 1 | ITER 0 | AVG_LOSS 0.5249624848365784 | Train_ACC 75.0\n",
      "EPOCH 1 | ITER 5 | AVG_LOSS 0.6870372295379639 | Train_ACC 56.25\n",
      "EPOCH 1 | ITER 10 | AVG_LOSS 0.5799237489700317 | Train_ACC 75.0\n",
      "EPOCH 1 | ITER 15 | AVG_LOSS 0.6309846639633179 | Train_ACC 68.75\n",
      "EPOCH 1 | ITER 20 | AVG_LOSS 0.6676008105278015 | Train_ACC 53.125\n",
      "EPOCH 1 | ITER 25 | AVG_LOSS 0.6276887059211731 | Train_ACC 62.5\n",
      "EPOCH 1 | ITER 30 | AVG_LOSS 0.7060261964797974 | Train_ACC 59.375\n",
      "EPOCH 1 | ITER 35 | AVG_LOSS 0.7622465491294861 | Train_ACC 56.25\n",
      "EPOCH 1 | ITER 40 | AVG_LOSS 0.6118640899658203 | Train_ACC 75.0\n",
      "EPOCH 1 | ITER 45 | AVG_LOSS 0.6359679698944092 | Train_ACC 50.0\n",
      "EPOCH 1 | ITER 50 | AVG_LOSS 0.6004748940467834 | Train_ACC 71.875\n",
      "EPOCH 1 | ITER 55 | AVG_LOSS 0.5470731854438782 | Train_ACC 75.0\n",
      "EPOCH 1 | ITER 60 | AVG_LOSS 0.5562100410461426 | Train_ACC 71.875\n",
      "EPOCH 1 | ITER 65 | AVG_LOSS 0.606888473033905 | Train_ACC 71.875\n",
      "EPOCH 1 | ITER 70 | AVG_LOSS 0.5848211646080017 | Train_ACC 71.875\n",
      "EPOCH 1 | ITER 75 | AVG_LOSS 0.6342271566390991 | Train_ACC 65.625\n",
      "EPOCH 1 | ITER 80 | AVG_LOSS 0.6993970274925232 | Train_ACC 59.375\n",
      "EPOCH 1 | ITER 85 | AVG_LOSS 0.6132013201713562 | Train_ACC 68.75\n",
      "EPOCH 1 | ITER 90 | AVG_LOSS 0.6553777456283569 | Train_ACC 65.625\n",
      "EPOCH 1 | ITER 95 | AVG_LOSS 0.6511601209640503 | Train_ACC 68.75\n",
      "EPOCH 1 | ITER 100 | AVG_LOSS 0.6184885501861572 | Train_ACC 71.875\n",
      "EPOCH 1 | ITER 105 | AVG_LOSS 0.4768489897251129 | Train_ACC 90.625\n",
      "EPOCH 1 | ITER 110 | AVG_LOSS 0.5149466395378113 | Train_ACC 75.0\n",
      "EPOCH 1 | ITER 115 | AVG_LOSS 0.522860586643219 | Train_ACC 78.125\n",
      "EPOCH 1 | ITER 120 | AVG_LOSS 0.6050659418106079 | Train_ACC 68.75\n",
      "Val Accuracy: 56.25%\n",
      "Test Accuracy: 59.38%\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 1 | LOSS 0.5364463329315186 | TIME 870.1930010318756\n",
      "--------------------------------------------------\n",
      "\n",
      "EPOCH 2 | ITER 0 | AVG_LOSS 0.5920023322105408 | Train_ACC 71.875\n",
      "EPOCH 2 | ITER 5 | AVG_LOSS 0.6666262745857239 | Train_ACC 62.5\n",
      "EPOCH 2 | ITER 10 | AVG_LOSS 0.6400625109672546 | Train_ACC 59.375\n",
      "EPOCH 2 | ITER 15 | AVG_LOSS 0.6176551580429077 | Train_ACC 68.75\n",
      "EPOCH 2 | ITER 20 | AVG_LOSS 0.494487464427948 | Train_ACC 78.125\n",
      "EPOCH 2 | ITER 25 | AVG_LOSS 0.5169438719749451 | Train_ACC 71.875\n",
      "EPOCH 2 | ITER 30 | AVG_LOSS 0.6020939946174622 | Train_ACC 71.875\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    model = Model()\n",
    "    print(torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"using gpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 20\n",
    "\n",
    "    train_loader, val_loader ,test_loader = load_Data()\n",
    "    \n",
    "    history = open(r'.\\Checkpoint1\\history.csv','w')\n",
    "    history.write('epochs , trainloss , val_acc , test_acc \\n')\n",
    "\n",
    "    for epoch in range(0,epochs):\n",
    "#         print(epoch)\n",
    "        start = time.time()\n",
    "        train_loss,accuracy = train(model, train_loader, criterion, optimizer, epoch)\n",
    "        val_loss = val(model, val_loader, criterion, optimizer, epoch)\n",
    "        test_loss = test(model, test_loader, criterion, optimizer, epoch)\n",
    "#         val_loss = train(model, val_loader, criterion, optimizer, epoch)\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('EPOCH {} | LOSS {} | TIME {}'.format(epoch, train_loss, time.time() - start))\n",
    "        print('-' * 50)\n",
    "        print()\n",
    "\n",
    "\n",
    "        history.write('{},{},{},{},{}\\n'.format(epoch, train_loss,accuracy, val_loss , test_loss))\n",
    "        save_checkpoint({'epoch': epoch,'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),'loss' : train_loss}, r'.\\Checkpoint1\\checkpoint_{}.ckpt'.format(epoch))\n",
    "    history.close()\n",
    "    \n",
    "\n",
    "# Press the green button in the gutter to run the script.\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model , data_loader):\n",
    "    class2idx = {'Dog': 0, 'Cat': 1}\n",
    "    idx2class = { value : key for key,value in  class2idx.items() }\n",
    "    embeddings = np.array([])\n",
    "    labels = np.array([])\n",
    "    model.eval()\n",
    "    out_features = 1280\n",
    "    num_categories = 2\n",
    "    with torch.no_grad(): \n",
    "        for i,data in enumerate(data_loader):\n",
    "            images, labs = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            embeds = model.features[\"embeddings\"].reshape(-1, out_features)\n",
    "            embeddings = np.append(embeddings , embeds)\n",
    "            labels = np.append(labels,labs.cpu())\n",
    "    \n",
    "    model.train()\n",
    "    embeddings = embeddings.reshape(-1, 1280)\n",
    "    print(embeddings)\n",
    "    \n",
    "    c_labels = labels.reshape(-1 , 1).ravel()\n",
    "    tsne = TSNE(n_components=2).fit_transform(embeddings)\n",
    "    labels = np.array([ idx2class[ele] for ele in c_labels])\n",
    "    \n",
    "    cmap = cm.get_cmap('tab20')\n",
    "    \n",
    "    for lab in range(num_categories):\n",
    "        indices = (c_labels == lab)\n",
    "        plt.scatter(tsne[indices, 0],tsne[indices, 1],c=np.array(cmap(lab)).reshape(1, 4),label=lab,alpha=1)\n",
    "        plt.legend(fontsize='large', markerscale=2)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "train_loader, val_loader ,test_loader = load_Data()\n",
    "visualize(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test) \n",
    "print(y_expected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(data, labels, output_filename=None):\n",
    "\n",
    "    seaborn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    " \n",
    "    plt.title(\"Confusion Matrix - FOOD101 - DENSENET\")\n",
    " \n",
    "    seaborn.set(font_scale=1.4)\n",
    "    ax = seaborn.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    " \n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    " \n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    "    \n",
    "    plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "class2idx = {'cheesecake': 0, 'french_fries': 1, 'fried_rice': 2, 'garlic_bread': 3}\n",
    "\n",
    "idx2class = { value : key  for key , value in class2idx.items() }\n",
    " \n",
    "print(y_expected[0])\n",
    "\n",
    "y_true = [  idx2class[val.item()] for val in y_expected ]\n",
    "y_pred = [ idx2class[val.item()] for val in y_test ]\n",
    "\n",
    "\n",
    "print(y_true[:10])\n",
    "print(y_pred[:10])\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true , y_pred , labels=['cheesecake', 'french_fries', 'fried_rice', 'garlic_bread'])\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix , ['cheesecake', 'french_fries', 'fried_rice', 'garlic_bread'] , output_filename = \"confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
